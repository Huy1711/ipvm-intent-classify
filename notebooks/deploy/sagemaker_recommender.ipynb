{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML framework details\n",
    "framework = 'PYTORCH'\n",
    "framework_version = '2.5.1'\n",
    "\n",
    "# ML model details\n",
    "ml_domain = 'NATURAL_LANGUAGE_PROCESSING'\n",
    "ml_task = 'CLASSIFICATION'\n",
    "\n",
    "model = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import dotenv\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "BUCKET_NAME = os.getenv(\"AWS_BUCKET\")\n",
    "AWS_ROLE_ARN = os.getenv(\"AWS_ROLE_ARN\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "S3_KEY = \"sagemaker\"\n",
    "\n",
    "\n",
    "region = \"us-east-1\"\n",
    "sagemaker_client = boto3.client(\n",
    "    'sagemaker', \n",
    "    region_name=region, \n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "cpu_inference_image = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    instance_type=\"ml.t2.large\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "print(cpu_inference_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "gpu_inference_image = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    instance_type=\"ml.p5.48xlarge\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "print(gpu_inference_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now()\n",
    "string_date = current_date.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_package_group_name = \"intent-pytorch-inference-\" + string_date\n",
    "print(model_package_group_name)\n",
    "model_pacakge_group_response = sagemaker_client.create_model_package_group(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageGroupDescription=\"Intent classify models\",\n",
    ")\n",
    "\n",
    "print(model_pacakge_group_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('/Users/huynd/ipvm-intent-classify/deploy/intent/payload/test3.json', 'w') as f:\n",
    "#     json.dump({\"text\": \"give percentages of cloud dvr and hybrid in pysical security market in last 5 years list percentages for each year\"}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tarfile\n",
    "\n",
    "# def compress_model(model_path):\n",
    "#     dir_name = os.path.dirname(model_path)\n",
    "#     file_name = os.path.basename(model_path)\n",
    "#     archive_file_name = f\"{file_name}.tar.gz\"\n",
    "#     with tarfile.open(os.path.join(dir_name, archive_file_name), 'w:gz') as tar:\n",
    "#         tar.add(os.path.join(model_path, \"test1.json\"), arcname=\"test1.json\")\n",
    "#         tar.add(os.path.join(model_path, \"test2.json\"), arcname=\"test2.json\")\n",
    "#         tar.add(os.path.join(model_path, \"test3.json\"), arcname=\"test3.json\")\n",
    "\n",
    "#     return os.path.join(dir_name, archive_file_name)\n",
    "\n",
    "# compress_model(\"/Users/huynd/ipvm-intent-classify/deploy/intent/payload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "model_archive_name = \"/Users/huynd/ipvm-intent-classify/deploy/intent/model.tar.gz\"\n",
    "payload_archive_name = \"/Users/huynd/ipvm-intent-classify/payload.tar.gz\"\n",
    "# sample_payload_url = sagemaker.Session().upload_data(\n",
    "#     payload_archive_name, bucket=BUCKET_NAME, key_prefix=S3_KEY\n",
    "# )\n",
    "# model_url = sagemaker.Session().upload_data(\n",
    "#     model_archive_name, bucket=BUCKET_NAME, key_prefix=S3_KEY\n",
    "# )\n",
    "sample_payload_url = \"s3://ipvm-chatbot/sagemaker/payload.tar.gz\"\n",
    "model_url = \"s3://ipvm-chatbot/sagemaker/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_version_response = sagemaker_client.create_model_package(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelPackageDescription=\"PyTorch DistilBERT Inference Recommender\",\n",
    "    Domain=ml_domain,\n",
    "    Task=ml_task,\n",
    "    SamplePayloadUrl=sample_payload_url,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"ContainerHostname\": \"pytorch-distilbert\",\n",
    "                \"Image\": gpu_inference_image,\n",
    "                \"ModelDataUrl\": model_url,\n",
    "                \"Framework\": framework,\n",
    "                \"NearestModelName\": model,\n",
    "                \"Environment\": {\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "                    \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "                    \"SAGEMAKER_REGION\": region,\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": model_url,\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
    "            \"ml.inf1.xlarge\",\n",
    "            \"ml.inf1.2xlarge\",\n",
    "            \"ml.g4dn.xlarge\",\n",
    "            \"ml.g4dn.2xlarge\",\n",
    "            \"ml.g4dn.4xlarge\",\n",
    "            \"ml.p3.2xlarge\",\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"application/json\"],\n",
    "        \"SupportedResponseMIMETypes\": [],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(model_package_version_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ROLE_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region)\n",
    "\n",
    "default_job = \"pytorch-basic-recommender-job-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "default_response = client.create_inference_recommendations_job(\n",
    "    JobName=str(default_job),\n",
    "    JobDescription=\"PyTorch Inference Basic Recommender Job\",\n",
    "    JobType=\"Default\",\n",
    "    RoleArn=AWS_ROLE_ARN,\n",
    "    InputConfig={\"ModelPackageVersionArn\": model_package_version_response[\"ModelPackageArn\"]},\n",
    ")\n",
    "\n",
    "print(default_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(default_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "describe_inf_recommender_response = client.describe_inference_recommendations_job(JobName=str(default_job))\n",
    "while describe_inf_recommender_response[\"Status\"] == \"IN_PROGRESS\":\n",
    "    describe_inf_recommender_response = client.describe_inference_recommendations_job(JobName=str(default_job))\n",
    "    print(describe_inf_recommender_response[\"Status\"])\n",
    "    time.sleep(15)\n",
    "    \n",
    "print(f'Inference recommender completed job with status: {describe_inf_recommender_response[\"Status\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_inf_recommender_response = client.describe_inference_recommendations_job(JobName=default_job)\n",
    "describe_inf_recommender_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job_name = str(default_job)\n",
    "\n",
    "describe_inf_recommender_response = client.describe_inference_recommendations_job(JobName=job_name)\n",
    "\n",
    "data = [\n",
    "    {**x[\"EndpointConfiguration\"], **x[\"ModelConfiguration\"], **x[\"Metrics\"]}\n",
    "    for x in describe_inf_recommender_response[\"InferenceRecommendations\"]\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(\"VariantName\", inplace=True, axis=1)\n",
    "pd.set_option(\"max_colwidth\", 400)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_inf_recommender_response[\"InferenceRecommendations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_job_steps_response = client.list_inference_recommendations_job_steps(\n",
    "    JobName=str(default_job)\n",
    ")\n",
    "print(list_job_steps_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gpu_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gpu_test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cpu_test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = (\n",
    "    df.sort_values(by=[\"CostPerHour\"]).head(1)[\"InstanceType\"].to_string(index=False).strip()\n",
    ")\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = model_package_version_response[\"ModelPackageArn\"]\n",
    "print(\"ModelPackage Version ARN : {}\".format(model_package_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_packages_response = client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")\n",
    "list_model_packages_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version_arn = list_model_packages_response[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"]\n",
    "print(model_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.describe_model_package(ModelPackageName=model_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\": model_package_arn,\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "model_package_update_response = client.update_model_package(**model_package_update_input_dict)\n",
    "model_package_update_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pytorch-distilbert-intent-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Model name : {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\n",
    "    \"ModelPackageName\": model_version_arn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_respose = client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=AWS_ROLE_ARN, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(\"Model arn : {}\".format(create_model_respose[\"ModelArn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"pytorch-distilbert-intent-endpoint-config-\" + datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\"\n",
    ")\n",
    "\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTrafficVariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"intent-model-endpoint\"\n",
    "\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "\n",
    "create_endpoint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "input_data = {\"text\": \"Tell me about Evolv\"}\n",
    "payload = json.dumps(input_data)\n",
    "start = time.time()\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "print(f\"took {time.time() - start}s\")\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intent-classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
