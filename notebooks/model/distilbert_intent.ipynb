{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "label_to_id_dict = {\n",
    "    \"general_information\": 0,\n",
    "    \"account_help\": 1,\n",
    "    \"troubleshoot_product\": 2,\n",
    "    \"lookup_report\": 3,\n",
    "    \"lookup_person\": 4,\n",
    "}\n",
    "\n",
    "id_to_label_dict = {\n",
    "    0: \"general_information\",\n",
    "    1: \"account_help\",\n",
    "    2: \"troubleshoot_product\",\n",
    "    3: \"lookup_report\",\n",
    "    4: \"lookup_person\",\n",
    "}\n",
    "\n",
    "def load_dataset(file):\n",
    "    data, dataset = [], []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    for sent in data:\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"text\": sent[\"text\"], \n",
    "                \"label\": label_to_id_dict[sent[\"label\"]],\n",
    "            }\n",
    "        )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_dataset(\"../../data/7k_sentences_train.jsonl\")\n",
    "eval_data = load_dataset(\"../../data/7k_sentences_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_len):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        text = data[\"text\"]\n",
    "        label = data[\"label\"]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(label, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "training_set = TextClassificationDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = TextClassificationDataset(eval_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    i=0\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        if i%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples\n",
    "            print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "            print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "        i+=1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    acc = validation(model, testing_loader)\n",
    "    return model, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model, acc = train(epoch)\n",
    "    torch.save(model.state_dict(), f\"./checkpoints/distilbert-7k-epoch-{epoch}-val-acc-{acc:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 2.032283067703247\n",
      "Validation Accuracy per 100 steps: 0.0\n",
      "Validation Loss Epoch: 1.5748355927921476\n",
      "Validation Accuracy Epoch: 34.523809523809526\n",
      "Accuracy on test data = 34.52%\n"
     ]
    }
   ],
   "source": [
    "acc = validation(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "model = DistillBERTClass()\n",
    "model.load_state_dict(torch.load(\"checkpoints/distilbert-7k-epoch-6-val-acc-88.0952\", weights_only=True))\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs.to(\"cpu\"))\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Show me reports about Hikvision.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Find the article on Axis cameras.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Get me the latest post on cybersecurity.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Give me reports on cloud computing.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Where is the report about AI trends?\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Fetch the post on video surveillance.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Find reports about IoT devices.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Show articles on machine learning.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Get the latest report on camera systems.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Get the latest post about facial recognition.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Give me the article on AI ethics.\n",
      "Predict: lookup_person | Ground truth: lookup_report\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I reset my password?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: I can't log in to my account. Can you help?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I update my email address?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: My account has been locked. What should I do?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How can I change my account settings?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: I need help recovering my account.\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I delete my account?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Can you help me upgrade my subscription?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why am I being charged for my account?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I manage my payment methods?\n",
      "Predict: lookup_person | Ground truth: account_help\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What's Mike Mathes working on lately?\n",
      "Predict: lookup_report | Ground truth: lookup_person\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I configure IP addresses on Axis cameras?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why is my Hikvision camera not recording footage?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I install Genetec Security Center on a new server?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What's the best way to adjust focus on a Hanwha Techwin PTZ camera?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why is my Dahua NVR not detecting connected cameras?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I troubleshoot Verkada camera connectivity issues?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I set up motion detection on a Bosch security camera?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I install a LenelS2 access control reader?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why is my Avigilon system not displaying live video?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I reset passwords for Paxton Net2 access control?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why isn't my Genetec AutoVu license plate recognition system working?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I configure door schedules in the Gallagher access control system?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I troubleshoot badge swipe issues on a Honeywell access reader?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What's the process for installing Milestone XProtect VMS?\n",
      "Predict: lookup_report | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I set up dual authentication on an HID Global access control panel?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Why isn't my Axis camera showing in the VMS?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I calibrate video analytics on a FLIR thermal camera?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What's the best way to install a door strike with a Brivo access system?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I configure remote access for a Mobotix camera?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How do I troubleshoot connection issues with an OpenPath access control system?\n",
      "Predict: lookup_person | Ground truth: troubleshoot_product\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Pros and cons of Axis vs Hanwha\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Quiz me about VSaaS\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How did Verkada pick its business model?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Write me an email explaining the pros and cons of CEIA and Evolv\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What are recent legal cases involving Flock\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Limitations of Avigilon Unity\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Single tenant cloud\n",
      "Predict: account_help | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What do I need to know about ZeroEyes?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Flipper zero for signal jamming\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Who is Minuteman?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Who makes Bolide cameras?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What is a 'pooling layer'?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Just fix the one I wrote then\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: You have to say FOIA in there somewhere we used a FOIA\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Yeah perfecto I can tweak that\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: What do you know about M.C. Dean?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How has the proportion of ZKTeco's overseas vs domestic sales evolved throughout the years?\n",
      "Predict: lookup_report | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: JCI acquired Tyco\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Resideo 2023 revenue?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Does Verkada give access to dealers like Alta does in terms of 'how' the reader communicates with the phone?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Do you know anything about HELIAUS by Allied Universal?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How is Dahua in the US operating now?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Verkada AD64\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Axis Q1605\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: How big is G4S?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Wavelynx Accelerate\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Does he have a position on AI?\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: Jones describes AI adoption as being in the 'early innings' - give me a direct quote\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence: I am going to interview him about these statements, give me some important and critical questions to ask him, in order from simple to complex and thought-provoking\n",
      "Predict: lookup_person | Ground truth: general_information\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Total wrong predictions: 71/84\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "for data in eval_data:\n",
    "    text = data[\"text\"]\n",
    "    label = id_to_label_dict[data[\"label\"]]\n",
    "    prediction = id_to_label_dict[predict(text)]\n",
    "    if prediction != label:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(\"Predict:\", prediction, \"| Ground truth:\", label)\n",
    "        print(\"-\"*80)\n",
    "        wrong += 1\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Total wrong predictions: {wrong}/{len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452380952380952"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong / len(eval_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intent-classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
