dataset:
  train:
    filepath:
      - ./data/14k_sentences_train.jsonl
    max_len: &max_len 512
    padding: &padding "max_length"
    augment: true

  val:
    filepath:
      - ./data/139_sentences_eval.jsonl
      - ./data/chatgpt-161-eval.jsonl
      - ./data/claude-100-eval.jsonl
    max_len: *max_len
    padding: *padding
    augment: false

  loaders:
    batch_size: 8
    num_workers: 0

model:
  num_classes: 5
  hidden_dim: 768
  dropout: 0.3

optimizer:
  lr: 1e-5
  weight_decay: 1e-2

callbacks:
  checkpointing:
    monitor: val_acc
    save_top_k: -1
    save_last: True
    filename: "{epoch}-{val_acc:.5f}"
    every_n_epochs: 1

loggers:
  tensorboard:
    save_dir: lightning_logs
    name: null
    version: null
    default_hp_metric: false

trainer:
  max_epochs: 30
  strategy: ddp_find_unused_parameters_false
  accelerator: gpu
  devices: [0, 1]
  fast_dev_run: false
